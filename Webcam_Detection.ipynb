{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeoJiWon1/Mask-detection/blob/main/Webcam_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mask Detect with Webcam"
      ],
      "metadata": {
        "id": "7Skxnji7zu9O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr6kkKa3zPHf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "import copy\n",
        "from PIL import Image\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Face & Mask Detector Preparation"
      ],
      "metadata": {
        "id": "GybNrrwAz2H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Face Detector Path\n",
        "face_dnn_model_name = 'C:/Users/user/Downloads/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "prototxt_name = 'C:/Users/user/Downloads/deploy.prototxt.txt'\n",
        "\n",
        "# Mask Detector Path\n",
        "# file_path = 'C:/Users/user/Downloads/mask_detector_resnet101.pth'\n",
        "file_path = 'C:/Users/user/Downloads/mask_detector_mobilenet.pth'"
      ],
      "metadata": {
        "id": "JcA-leV_zWay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 객체 생성\n",
        "face_detector = cv2.dnn.readNetFromCaffe(prototxt_name, face_dnn_model_name)\n",
        "mask_detector = torch.load(file_path)"
      ],
      "metadata": {
        "id": "5EZR8rCF0C86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수 설정\n",
        "# 얼굴 인식 최소 신뢰도\n",
        "min_confidence = 0.3\n",
        "\n",
        "# 이미지 크기\n",
        "frame_width = 700\n",
        "\n",
        "# Label\n",
        "class_names = ['with_mask', 'without_mask']"
      ],
      "metadata": {
        "id": "-ySDwyTMzdPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 전처리 메서드\n",
        "def process_image(image):\n",
        "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
        "        returns an Numpy array\n",
        "    '''\n",
        "    \n",
        "    # TODO: Process a PIL image for use in a PyTorch model\n",
        "#     pil_image = Image.open(image)\n",
        "    pil_image = image\n",
        "   \n",
        "    image_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    img = image_transforms(pil_image)\n",
        "    return img"
      ],
      "metadata": {
        "id": "_uabITpt0JsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mask Detection Method"
      ],
      "metadata": {
        "id": "1qY1y_k28QEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask Detection 메서드\n",
        "def classify_mask(image):\n",
        "    device = torch.device(\"cpu\")\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    img = Image.fromarray(image)\n",
        "    image = process_image(img)\n",
        "    print('image_processed')\n",
        "    img = image.unsqueeze_(0)\n",
        "    img = image.float()\n",
        "\n",
        "    mask_detector.eval()\n",
        "    mask_detector.cpu()\n",
        "    output = mask_detector(image)\n",
        "    print(output,'##############output###########')\n",
        "    check, predicted = torch.max(output, 1)\n",
        "    print(predicted.data[0],\"predicted\")\n",
        "\n",
        "\n",
        "    classification = predicted.data[0]\n",
        "    index = int(classification)\n",
        "    print(class_names[index])\n",
        "    return class_names[index]"
      ],
      "metadata": {
        "id": "l7uO5vH80UxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect And Display Method"
      ],
      "metadata": {
        "id": "cn_qkwkb8Nn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 받아서 얼굴 인식 및 마스크 탐지 진행 후 반환 처리하는 메서드\n",
        "def detectAndDisplay(frame):\n",
        "    # frame_width 에 맞춰서 image resize\n",
        "    # height, width = frame.shape[:2]\n",
        "    (height, width) = frame.shape[:2]\n",
        "    ratio = frame_width / width\n",
        "    dimension = (frame_width, int(height * ratio))\n",
        "    frame = cv2.resize(frame, dimension, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "    # 이미지를 300 x 300으로 size 조정하고 blob 만들기\n",
        "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), scalefactor=1.0,\n",
        "                                 size=(300, 300), mean=(104.0, 177.0, 123.0))    \n",
        "    \n",
        "    # blob 모델에 넣고 얼굴 detection 수행\n",
        "    face_detector.setInput(blob)\n",
        "    face_detections = face_detector.forward()\n",
        "\n",
        "    result_frame = frame.copy()\n",
        "\n",
        "    # Detections 한 수만큼 루프 돌기\n",
        "    for i in range(0, face_detections.shape[2]):\n",
        "        confidence = face_detections[0, 0, i, 2] # confidence는 detection한 확률\n",
        "\n",
        "        # min_confidence 보다 큰 경우에만 detection으로 인정함\n",
        "        if confidence > min_confidence:\n",
        "            # box 좌표 구하기\n",
        "            # box = face_detections[0, 0, i, 3:7] * np.array([frame_width, height, frame_width, height])\n",
        "            box = face_detections[0, 0, i, 3:7] * np.array([frame_width, int(height * ratio), frame_width, int(height * ratio)])\n",
        "            (x1, y1, x2, y2) = box.astype('int')\n",
        "            \n",
        "            # 얼굴 이미지 자르기\n",
        "            face_input = frame[y1:y2, x1:x2]\n",
        "\n",
        "            # 얼굴 이미지를 모델에 넣기\n",
        "            label = classify_mask(face_input)\n",
        "            print(f'Label : {label}')\n",
        "            \n",
        "            # 마스크 인식 결과 비교\n",
        "            if label == 'with_mask':\n",
        "                color = (0, 255, 0)\n",
        "            else:\n",
        "                color = (0, 0, 255)\n",
        "\n",
        "            # 얼굴에 사각형 그리기\n",
        "            cv2.rectangle(result_frame, pt1=(x1, y1), pt2=(x2, y2), thickness=2, color=color, lineType=cv2.LINE_AA)\n",
        "            cv2.putText(result_frame, text=label, org=(x1, y1 - 10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.8, color=color, thickness=2, lineType=cv2.LINE_AA)\n",
        "\n",
        "    # 결과 출력\n",
        "    cv2.imshow('frame', result_frame)"
      ],
      "metadata": {
        "id": "X81h4vgd0je2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Webcam Input & Output"
      ],
      "metadata": {
        "id": "vbVbxafO8GlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Webcam 입출력\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_width)\n",
        "\n",
        "if cap.isOpened():\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            detectAndDisplay(frame)\n",
        "            if cv2.waitKey(1) != -1:\n",
        "                break\n",
        "        \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "OWhg-anW18Jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Face Tracking\n",
        "- Tracking이 Detection보다 자원 소모가 적고 처리속도가 빠르다\n",
        "- 처음에만 Detection하고 이후에는 Tracking을 해서 부드럽게 추적하도록 구현\n",
        "- 시도를 해보고 있지만 안될수 있음.."
      ],
      "metadata": {
        "id": "N7y6yW5o8T1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5AVVeBMm8Vg-",
        "outputId": "cca2f5f2-ae43-4c3d-b7d4-3ad0d4b9f081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Object Tracker Mode 설정\n",
        "tracker = cv2.legacy.TrackerKCF_create()"
      ],
      "metadata": {
        "id": "aI0xwOK08cIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수 초기화\n",
        "detected = False\n",
        "frame_mode = 'Tracking'"
      ],
      "metadata": {
        "id": "dNeOzUTl8ja3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 카메라 동영상 로드\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_width)\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_width)\n",
        "\n",
        "# 원본 동영상 오픈 여부 확인\n",
        "if not cap.isOpened:\n",
        "    print('--(!) Error opening video capture')\n",
        "    exit(0)\n",
        "\n",
        "# trakers 객체 생성\n",
        "# OvenCV 4.6.0 이후는 legacy에 들어가있음!! 버전 확인\n",
        "trackers = cv2.legacy.MultiTracker_create()\n",
        "\n",
        "if cap.isOpened():\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        (height, width) = frame.shape[:2]\n",
        "        ratio = frame_width / width\n",
        "        dimension = (frame_width, int(height * ratio))\n",
        "        frame = cv2.resize(frame, dimension, interpolation = cv2.INTER_AREA)\n",
        "        \n",
        "        if ret:\n",
        "            # 얼굴인식-추적, 객체 탐지\n",
        "            if detected:\n",
        "                frame_mode = 'Tracking'\n",
        "                ret, boxes = trackers.update(frame)\n",
        "                \n",
        "                for box in boxes:\n",
        "                    (x1, y1, x2, y2) = [int(v) for v in box]\n",
        "                \n",
        "                # 얼굴 이미지 자르기\n",
        "                face_input = frame[y1:y2, x1:x2]\n",
        "                \n",
        "                # 얼굴 이미지를 모델에 넣기\n",
        "                label = classify_mask(face_input)\n",
        "                print(f'Label : {label}')\n",
        "                \n",
        "                # 마스크 인식 결과 비교\n",
        "                if label == 'with_mask':\n",
        "                    color = (0, 255, 0)\n",
        "                    label = 'With Mask %d%%' % (confidence * 100)\n",
        "                else:\n",
        "                    color = (0, 0, 255)\n",
        "                    label = 'Without Mask %d%%' % (confidence * 100)\n",
        "\n",
        "                # 얼굴에 사각형 그리기\n",
        "                cv2.rectangle(frame, pt1=(x1, y1), pt2=(x2, y2), thickness=2, color=color, lineType=cv2.LINE_AA)\n",
        "                cv2.putText(frame, text=label, org=(x1, y1 - 10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.8, color=color, thickness=2, lineType=cv2.LINE_AA)\n",
        "                cv2.putText(frame,text=str(frame_mode),org=(100,height-20), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1,color=(255,255,255),thickness=1,lineType=cv2.LINE_AA)\n",
        "            \n",
        "            else:\n",
        "                frame_mode = 'Detection'\n",
        "\n",
        "                blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), scalefactor=1.0,\n",
        "                                     size=(300, 300), mean=(104.0, 177.0, 123.0))    \n",
        "                \n",
        "                # blob 모델에 넣고 얼굴 detection 수행\n",
        "                face_detector.setInput(blob)\n",
        "                face_detections = face_detector.forward()\n",
        "                \n",
        "                # Detections 한 수만큼 루프 돌기\n",
        "                for i in range(0, face_detections.shape[2]):\n",
        "                    confidence = face_detections[0, 0, i, 2] # confidence는 detection한 확률\n",
        "\n",
        "                    # min_confidence 보다 큰 경우에만 detection으로 인정함\n",
        "                    if confidence > min_confidence:\n",
        "                        # box 좌표 구하기\n",
        "                        box = face_detections[0, 0, i, 3:7] * np.array([frame_width, int(height * ratio), frame_width, int(height * ratio)])\n",
        "                        (x1, y1, x2, y2) = box.astype('int')\n",
        "\n",
        "                        # 얼굴 이미지 자르기\n",
        "                        face_input = frame[y1:y2, x1:x2]\n",
        "\n",
        "                        # 얼굴 이미지를 모델에 넣기\n",
        "                        label = classify_mask(face_input)\n",
        "                        print(f'Label : {label}')\n",
        "\n",
        "                        # 마스크 인식 결과 비교\n",
        "                        if label == 'with_mask':\n",
        "                            color = (0, 255, 0)\n",
        "                            label = 'With Mask %d%%' % (confidence * 100)\n",
        "                        else:\n",
        "                            color = (0, 0, 255)\n",
        "                            label = 'Without Mask %d%%' % (confidence * 100)\n",
        "\n",
        "                        # 얼굴에 사각형 그리기\n",
        "                        cv2.rectangle(frame, pt1=(x1, y1), pt2=(x2, y2), thickness=2, color=color, lineType=cv2.LINE_AA)\n",
        "                        cv2.putText(frame, text=label, org=(x1, y1 - 10), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.8, color=color, thickness=2, lineType=cv2.LINE_AA)\n",
        "                        cv2.putText(frame,text=str(frame_mode),org=(100,height-20), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1,color=(255,255,255),thickness=1,lineType=cv2.LINE_AA)\n",
        "                        \n",
        "                # trackers 객체가 설정된 tracker mode로 boxing된 영역 tracking\n",
        "                trackers.add(tracker, frame, (x1, y1, x2, y2))\n",
        "                detected = True # detected mode 변경\n",
        "            \n",
        "            cv2.imshow('frame', frame)\n",
        "            if cv2.waitKey(1) != -1:\n",
        "                break\n",
        "        \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Hc0elAdo8wAS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}